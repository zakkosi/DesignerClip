# R_server.py (ìµœì¢… ì™„ì„±ë³¸)

import os
import uuid
import shutil
import subprocess
from pathlib import Path
from typing import Dict
import uvicorn
import json
from openai import OpenAI
# BackgroundTasksë¥¼ fastapiì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
from fastapi import FastAPI, Form, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from dotenv import load_dotenv
from inference_engine import ColPaliRetriever 

class LLMOrchestrator:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.client = OpenAI(api_key=self.api_key)
        print("LLMOrchestrator: Initialized with new integrated prompt.")

    def parse_user_request(self, text: str) -> Dict[str, str]:
        print(f"LLM: Parsing text with GPT -> '{text}'")
        
        # ë™ë£Œë¶„ì˜ ì•„ì´ë””ì–´ì™€ ê¸°ì¡´ í›„ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­ì„ í†µí•©í•œ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸
        system_instruction = f"""
        ë„ˆëŠ” ì£¼ì–´ì§„ ë¬¸ì¥ì—ì„œ 'í˜„ì¬ ì§€ì¹­í•˜ëŠ” ì˜·(source)'ê³¼ 'ì ìš©í•˜ê³  ì‹¶ì€ ì˜·(target)'ì„ ì°¾ì•„ì„œ, í›„ì† ì‘ì—…ì— í•„ìš”í•œ ë‘ ê°€ì§€ í‚¤ë¥¼ ê°€ì§„ JSON ê°ì²´ë¡œ ë°˜í™˜í•˜ëŠ” AIì•¼.
        ë°˜í™˜í•  JSONì˜ í‚¤ëŠ” "pbr_prompt"ì™€ "db_query" ì—¬ì•¼ í•´.

        ì‚¬ìš©ì ë¬¸ì¥: "{text}"

        ì‘ì—… ì§€ì‹œ:
        1. ë¬¸ì¥ì—ì„œ 'source'ì™€ 'target'ì„ ì •í™•íˆ íŒŒì•…í•´ì¤˜.
        2. "pbr_prompt": íŒŒì•…í•œ 'source'ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ê³ , "english_word ." í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜. (ì˜ˆ: 'íŒŒë€ìƒ‰ ì…”ì¸ ' -> 'blue shirt .')
        3. "db_query": íŒŒì•…í•œ 'target'ì˜ í•µì‹¬ í‚¤ì›Œë“œë§Œ ë‹¨ìˆœ ë¬¸ìì—´ë¡œ ë§Œë“¤ì–´ì¤˜. (ì˜ˆ: 'ì²­ë°”ì§€ ë“œë ˆìŠ¤' -> 'ì²­ë°”ì§€ ë“œë ˆìŠ¤')
        4. ë§Œì•½ sourceë‚˜ targetì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ í•´ë‹¹ ê°’ì€ nullë¡œ ì„¤ì •í•´ì¤˜.
        5. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ìµœì¢… JSON ê°ì²´ë§Œ ë°˜í™˜í•´.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "system", "content": system_instruction}],
                response_format={"type": "json_object"}
            )
            result = json.loads(response.choices[0].message.content)
            
            pbr_prompt = result.get("pbr_prompt")
            db_query = result.get("db_query")

            # Null ê°’ì— ëŒ€í•œ ê¸°ë³¸ê°’ ì²˜ë¦¬
            if not pbr_prompt: pbr_prompt = "object ."
            if not db_query: db_query = ""
            
            print(f"LLM -> PBR Prompt: '{pbr_prompt}', DB Query: '{db_query}'")
            return {"pbr_prompt": pbr_prompt, "db_query": db_query}

        except Exception as e:
            print(f"LLM ERROR: Failed to parse with GPT. Error: {e}")
            raise HTTPException(status_code=500, detail="LLM processing failed.")


# --- ì´ˆê¸° ì„¤ì • ë° ëª¨ë¸ ë¡œë”© ---
print("ğŸš€ ì„œë²„ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

OUTPUT_DIR = Path("MaterialPalette") / "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

DB_FOLDER_PATH = "dress-data" 
retriever = ColPaliRetriever(db_folder_path=DB_FOLDER_PATH, model_name="tsystems/colqwen2.5-3b-multilingual-v1.0")
llm_orchestrator = LLMOrchestrator(api_key=OPENAI_API_KEY)

app = FastAPI()
print("âœ… ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ. ìš”ì²­ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.")

@app.get("/")
async def get_test_page():
    return FileResponse("test.html")

@app.post("/apply-style")
async def apply_style(
    background_tasks: BackgroundTasks, 
    text: str = Form(...), 
    image: UploadFile = File(...)
):
    print(f"\n\n--- ìƒˆë¡œìš´ ìš”ì²­ ìˆ˜ì‹  ---")
    print(f"ì…ë ¥ í…ìŠ¤íŠ¸: '{text}'")
    print(f"ì…ë ¥ ì´ë¯¸ì§€: '{image.filename}'")

    # --- íŒŒì¼ ì´ë¦„ ê·œì¹™ ë³€ê²½ ---
    image_basename = Path(image.filename).stem 
    
    # ìµœì¢… PBR ì‘ì—… í´ë” ê²½ë¡œ: MaterialPalette/output/<íŒŒì¼ëª…>/
    pbr_working_dir = OUTPUT_DIR / image_basename
    os.makedirs(pbr_working_dir, exist_ok=True)

    target_image_path = pbr_working_dir / image.filename
    with open(target_image_path, "wb") as buffer:
        shutil.copyfileobj(image.file, buffer)
    print(f"PBR íŒŒì´í”„ë¼ì¸ì„ ìœ„í•´ ì´ë¯¸ì§€ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {target_image_path}")

    try:
        # --- ë¹ ë¥¸ ì‘ì—…: LLM ë¶„ì„ ë° ColPali ê²€ìƒ‰ ---
        parsed_keywords = llm_orchestrator.parse_user_request(text)
        pbr_prompt = parsed_keywords["pbr_prompt"]
        db_query = parsed_keywords["db_query"]

        print(f"\n[Immediate Task] DBì—ì„œ '{db_query}' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
        retrieved_items = retriever.search(query_text=db_query, k=1)
        if not retrieved_items:
            raise HTTPException(status_code=404, detail=f"'{db_query}'ì— í•´ë‹¹í•˜ëŠ” ì•„ì´í…œì„ DBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        target_filename = retrieved_items[0]['metadata']['image_name']
        print(f"âœ… [Immediate Task] DB ê²€ìƒ‰ ì™„ë£Œ! Target Filename: {target_filename}")

        # --- ëŠë¦° ì‘ì—…: PBR ìƒì„±ì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì „ë‹¬ ---
        print("\n[Background Task] PBR ìƒì„±ì„ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì˜ˆì•½í•©ë‹ˆë‹¤...")
        background_tasks.add_task(run_pbr_generation_pipeline, target_image_path, pbr_prompt)

        # --- ì¦‰ì‹œ ì‘ë‹µ ---
        final_response = {"target_filename": target_filename}
        print("\nìš”ì²­ ì²˜ë¦¬ ì„±ê³µ. Unityë¡œ ì¦‰ì‹œ ì‘ë‹µì„ ì „ì†¡í•©ë‹ˆë‹¤. PBR ìƒì„±ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì†ë©ë‹ˆë‹¤.")
        return JSONResponse(content=final_response)

    except Exception as e:
        # ì£¼ìš” ë¡œì§ì—ì„œ ë°œìƒí•œ ì˜¤ë¥˜ëŠ” ì—¬ê¸°ì„œ ì²˜ë¦¬
        print(f"ğŸš¨ ì¦‰ì‹œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„±ëœ í´ë” ì •ë¦¬
        if 'pbr_working_dir' in locals() and pbr_working_dir.exists():
            shutil.rmtree(pbr_working_dir)
            print(f"ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ì„ì‹œ PBR ì‘ì—… í´ë”ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤: {pbr_working_dir}")
        if isinstance(e, HTTPException):
            raise e
        raise HTTPException(status_code=500, detail=str(e))

def run_pbr_generation_pipeline(image_path: Path, prompt: str):
    """
    PBR ìƒì„± íŒŒì´í”„ë¼ì¸ ì „ì²´ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜. ì´ì œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.
    """
    print(f"\n--- InBackground: PBR íŒŒì´í”„ë¼ì¸ ì‹œì‘ (ì´ë¯¸ì§€: {image_path.name}) ---")
    try:
        command = [
            "python", "run_full_pipeline.py",
            "--image_path", str(image_path),
            "--prompt", prompt
        ]
        print(f"InBackground: PBR íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: {' '.join(command)}")
        process = subprocess.run(command, capture_output=True, text=True, check=True, encoding='utf-8')
        print("InBackground: PBR íŒŒì´í”„ë¼ì¸ stdout:", process.stdout)
        
        # PBR ê²°ê³¼ë¬¼ì€ ì‚­ì œí•˜ì§€ ì•Šê³  ìœ ì§€
        print(f"--- âœ… InBackground: PBR íŒŒì´í”„ë¼ì¸ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ (ì´ë¯¸ì§€: {image_path.name}) ---")
        
    except Exception as e:
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ê¸°ë¡
        print(f"--- ğŸš¨ InBackground: PBR íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜ ë°œìƒ (ì´ë¯¸ì§€: {image_path.name}) ---")
        if isinstance(e, subprocess.CalledProcessError):
            print(f"  - Stderr: {e.stderr}")
        else:
            print(f"  - Exception: {e}")
        # ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë”ë¼ë„ ìƒì„±ëœ í´ë”ëŠ” ë””ë²„ê¹…ì„ ìœ„í•´ ì¼ë‹¨ ë‚¨ê²¨ë‘˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # í•„ìš” ì‹œ ì—¬ê¸°ì— í´ë” ì‚­ì œ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥: shutil.rmtree(image_path.parent)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)